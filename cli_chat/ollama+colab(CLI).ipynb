{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b51adb6dce344e998e8d09a30cea3d79": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b2fa9b8161bb4058bbceb0363da1e3a4",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32mâ ‹\u001b[0m \u001b[1;95mðŸ¤” Thinking...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â ‹</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ðŸ¤” Thinking...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "b2fa9b8161bb4058bbceb0363da1e3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147ff1f6e1ca4ff1abdb6e51ac1591d5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_218ecabdd2ca45c7a54a325965f61963",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32mâ §\u001b[0m \u001b[1;95mðŸ¤” Thinking...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â §</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ðŸ¤” Thinking...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "218ecabdd2ca45c7a54a325965f61963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a505a4ef774f5c990fdc55fc030f6f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_935338c8490a42c0b24a89183fe786b4",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32mâ ¸\u001b[0m \u001b[1;95mðŸ¤” Thinking...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â ¸</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ðŸ¤” Thinking...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "935338c8490a42c0b24a89183fe786b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Colab + Ollama  \n",
        "---\n",
        "## Install ollama on colab and use cloud gpu to run any Open source **L**arge **L**anguage **M**odel\n",
        "---\n",
        "### steps to follow before installing ollama\n",
        "- change connection type from CPU to T4 GPU\n",
        "\n"
      ],
      "metadata": {
        "id": "xLKXoLmeLVWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!apt-get install zstd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1OK9EjZa8Zan",
        "outputId": "08a241f5-f399-4069-c6ad-8ffd8c571ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zstd is already the newest version (1.4.8+dfsg-3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install ollama"
      ],
      "metadata": {
        "id": "m_RuOXvuLaCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os8a5Ajq8kG9",
        "outputId": "3e6282c3-f107-4ff0-d943-a90baf6004e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading ollama-linux-amd64.tar.zst\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running next cell open terminal from bottom left of window and run `ollama serve` in terminal.\n",
        "> It will run ollama server in background, we will need it's service to Download ,Install and Run LLM's  "
      ],
      "metadata": {
        "id": "7fgyBGBTLn_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "run this command\n",
        "`ollama pull <model-name>`  to install LLM or run `ollama run <model-name>` to install and run  \\\n",
        " Replace `<model-name>` with llm name you want to install, I will be installing Gemma 3\n",
        "### List of llms from ollama GitHub\n",
        "\n",
        "## Model library\n",
        "\n",
        "Ollama supports a list of models available on [ollama.com/library](https://ollama.com/library \"ollama model library\")\n",
        "\n",
        "Here are some example models that can be downloaded:\n",
        "\n",
        "| Model              | Parameters | Size  | Download                         |\n",
        "| ------------------ | ---------- | ----- | -------------------------------- |\n",
        "| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |\n",
        "| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |\n",
        "| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |\n",
        "| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |\n",
        "| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |\n",
        "| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |\n",
        "| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |\n",
        "| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |\n",
        "| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |\n",
        "| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |\n",
        "| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |\n",
        "| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |\n",
        "| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |\n",
        "| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |\n",
        "| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |\n",
        "| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |\n",
        "| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |\n",
        "| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |\n",
        "| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |\n",
        "| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |\n",
        "| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |\n",
        "| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |\n",
        "| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |\n",
        "| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |\n",
        "| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |\n",
        "| Granite-3.3        | 8B         | 4.9GB | `ollama run granite3.3`          |\n",
        "\n",
        "> [!NOTE]\n",
        "> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n"
      ],
      "metadata": {
        "id": "ihayUeSkLq8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull gemma3:12b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O0kTzKY81RN",
        "outputId": "47f04823-7644-4ebe-f695-d4783312c1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.text import Text\n",
        "from rich.prompt import Prompt\n",
        "from rich.markdown import Markdown\n",
        "import time\n",
        "from ollama import chat"
      ],
      "metadata": {
        "id": "qhSZEYMT5yl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "console = Console()"
      ],
      "metadata": {
        "id": "Wlk7XMnF5y7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_llm(prompt, history=None,model='gemma3:1b'):\n",
        "    messages = []\n",
        "    if history:\n",
        "        for u, b in history:\n",
        "            messages.append({\"role\": \"user\", \"content\": u})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": b})\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    response = chat(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        stream=False\n",
        "    )\n",
        "    return response[\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "yr6yM9Ys9Uja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def chat(txt: str) -> str:\n",
        "#     \"\"\"Simulated chat function - replace with your actual implementation\"\"\"\n",
        "#     time.sleep(0.5)  # Simulate processing time\n",
        "#     return f\"Echo: {txt}\"\n",
        "ask_llm(\"why ocean is blue\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "collapsed": true,
        "id": "blh23PVG70GP",
        "outputId": "e7dcb281-6d5c-40c6-8ad3-2f9a2c171c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The blue color of the ocean is a fascinating phenomenon caused by a process called **selective absorption and scattering of sunlight**. Hereâ€™s a breakdown of the key reasons:\\n\\n**1. Rayleigh Scattering:**\\n\\n* **The Primary Reason:** The main reason the ocean appears blue is due to a phenomenon called **Rayleigh scattering**. This happens when sunlight hits tiny particles in the water, like water molecules and sediment.\\n* **Shorter Wavelengths Scatter More:**  Rayleigh scattering is much more effective at scattering light with shorter wavelengths â€“ blue and violet light.  Think of it like a tiny laser beam â€“ it bounces off these particles much more easily than longer wavelengths like red and orange.\\n* **Why Not Violet?** Violet light is scattered even *more* than blue, but the sun emits less violet light, and our eyes are less sensitive to it. This is why we primarily see the blue color.\\n\\n\\n**2. Other Factors Contributing to the Blue Hue:**\\n\\n* **Water Depth & Depth of Blue Color:**  The deeper the water, the more blue light is scattered.  This is why the ocean appears much more blue when itâ€™s deeper.\\n* **Suspended Particles:**  The presence of things like plankton, seaweed, and sediment in the water can also influence how light is scattered and absorbed.  These particles scatter blue light, making the water appear a slightly darker blue. \\n* **Sun Angle & Time of Day:** The sunâ€™s position affects how much light reaches the surface. During sunrise and sunset, the sun's rays are angled more directly, scattering more of the blue light and increasing the intensity of the orange and red colors.\\n\\n\\n**In short, the blue color of the ocean is a beautiful result of light bouncing around in the water!**\\n\\n**Important Note:**  While blue is the most prominent color, the ocean can also appear greenish, brownish, or even reddish depending on factors like sediment composition and depth. \\n\\n---\\n\\n**Want to learn more? Here are some resources:**\\n\\n* **National Geographic - Why is the Ocean Blue?** [https://www.nationalgeographic.com/science/2017/03/why-is-the-ocean-blue](https://www.nationalgeographic.com/science/2017/03/why-is-the-ocean-blue)\\n* **NASA - Ocean Colors:** [https://science.nasa.gov/ocean-colors/](https://science.nasa.gov/ocean-colors/)\\n\\nDo you have any other questions about the ocean or light scattering?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def start_chat(model='gemma3:1b'):\n",
        "  history = []\n",
        "  while True:\n",
        "    prompt = input(\"\\nask-> \")\n",
        "    if prompt in ('/bye', 'exit'): break\n",
        "    response = ask_llm(prompt=prompt,history=history,model=model)\n",
        "    print(\"\\n\",response)\n",
        "    history.append((prompt,response))\n",
        "  return history"
      ],
      "metadata": {
        "id": "VzPCCqlq99Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_message_bubble(text: str, is_user: bool = True) -> Panel:\n",
        "    \"\"\"Create a styled message bubble optimized for Colab\"\"\"\n",
        "    if is_user:\n",
        "        return Panel(\n",
        "            Text(text, style=\"bold bright_cyan\"),\n",
        "            border_style=\"bold bright_blue\",\n",
        "            title=\"[bold bright_white on bright_blue] ðŸ‘¤ YOU [/bold bright_white on bright_blue]\",\n",
        "            title_align=\"left\",\n",
        "            padding=(1, 2),\n",
        "            width=100\n",
        "        )\n",
        "    else:\n",
        "        markdown_content = Markdown(text, code_theme=\"monokai\", inline_code_theme=\"monokai\")\n",
        "        return Panel(\n",
        "            markdown_content,\n",
        "            border_style=\"bold bright_magenta\",\n",
        "            title=\"[bold bright_white on bright_magenta]ðŸ¤–[/bold bright_white on bright_magenta]\",\n",
        "            title_align=\"left\",\n",
        "            padding=(1, 2),\n",
        "            width=100\n",
        "        )\n"
      ],
      "metadata": {
        "id": "OtZZ7wN972PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main(model='gemma3:1b'):\n",
        "    # Header with bold colors\n",
        "    header = Panel(\n",
        "        Text(f\"ðŸ’¬ {model} ðŸ’¬\", style=\"bold bright_yellow\", justify=\"center\"),\n",
        "        border_style=\"bold bright_yellow\",\n",
        "        padding=(1, 2),\n",
        "        subtitle=\"[bold bright_white]Type 'quit' or 'exit' or '/bye' to end conversation[/bold bright_white]\",\n",
        "        subtitle_align=\"center\"\n",
        "    )\n",
        "    console.print(header)\n",
        "    console.print()\n",
        "\n",
        "    conversation_history = []\n",
        "    history = []\n",
        "    while True:\n",
        "        # Get user input with bold prompt\n",
        "        console.print()\n",
        "        try:\n",
        "            user_input = Prompt.ask(\"[bold bright_green]askâ–¶[/bold bright_green]\")\n",
        "        except (KeyboardInterrupt, EOFError):\n",
        "            break\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', '/bye']:\n",
        "            console.print()\n",
        "            console.print(Panel(\n",
        "                Text(\"ðŸ‘‹ Goodbye! Thanks for chatting!\", style=\"bold bright_cyan\", justify=\"center\"),\n",
        "                border_style=\"bold bright_green\",\n",
        "                padding=(1, 2)\n",
        "            ))\n",
        "            console.print()\n",
        "            break\n",
        "\n",
        "        if not user_input.strip():\n",
        "            continue\n",
        "\n",
        "        # Show thinking indicator with bold colors\n",
        "        with console.status(\"[bold bright_magenta]ðŸ¤” Thinking...\", spinner=\"dots\"):\n",
        "            response = ask_llm(user_input,history=history,model=model)\n",
        "\n",
        "        # Display assistant response\n",
        "        console.print(create_message_bubble(response, is_user=False))\n",
        "        history.append((user_input,response))\n",
        "        conversation_history.append({\n",
        "            'user': user_input,\n",
        "            'assistant': response\n",
        "        })\n"
      ],
      "metadata": {
        "id": "iYEdL4z376C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main('gemma3:12b') #replace gemmma3:12b with model you insalled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863,
          "referenced_widgets": [
            "b51adb6dce344e998e8d09a30cea3d79",
            "b2fa9b8161bb4058bbceb0363da1e3a4",
            "147ff1f6e1ca4ff1abdb6e51ac1591d5",
            "218ecabdd2ca45c7a54a325965f61963",
            "39a505a4ef774f5c990fdc55fc030f6f",
            "935338c8490a42c0b24a89183fe786b4"
          ]
        },
        "id": "aKSff1aF78IS",
        "outputId": "73da3d01-d5d9-420c-f803-d93dc373ffdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;93mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;93mâ”‚\u001b[0m                                                                                                                 \u001b[1;93mâ”‚\u001b[0m\n",
              "\u001b[1;93mâ”‚\u001b[0m  \u001b[1;93m                                              ðŸ’¬ gemma3:12b ðŸ’¬                                               \u001b[0m  \u001b[1;93mâ”‚\u001b[0m\n",
              "\u001b[1;93mâ”‚\u001b[0m                                                                                                                 \u001b[1;93mâ”‚\u001b[0m\n",
              "\u001b[1;93mâ•°â”€\u001b[0m\u001b[1;93mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;93m \u001b[0m\u001b[1;97mType 'quit' or 'exit' or '/bye' to end conversation\u001b[0m\u001b[1;93m \u001b[0m\u001b[1;93mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;93mâ”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â”‚</span>                                                                                                                 <span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â”‚</span>  <span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">                                              ðŸ’¬ gemma3:12b ðŸ’¬                                               </span>  <span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â”‚</span>                                                                                                                 <span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\">Type 'quit' or 'exit' or '/bye' to end conversation</span><span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;92maskâ–¶\u001b[0m: "
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">askâ–¶</span>: </pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ans in maximum 100 word\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b51adb6dce344e998e8d09a30cea3d79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;95mâ•­â”€\u001b[0m\u001b[1;95m \u001b[0m\u001b[1;97;105mðŸ¤–\u001b[0m\u001b[1;95m \u001b[0m\u001b[1;95mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;95mâ”€â•®\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  Please provide me with the question you want me to answer! I need the question to give you a    \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  response within the 100-word limit. ðŸ˜Š                                                          \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  I'm ready when you are!                                                                         \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â•­â”€ </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ff00ff; font-weight: bold\">ðŸ¤–</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  Please provide me with the question you want me to answer! I need the question to give you a    <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  response within the 100-word limit. ðŸ˜Š                                                          <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  I'm ready when you are!                                                                         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;92maskâ–¶\u001b[0m: "
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">askâ–¶</span>: </pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "who are you ?/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "147ff1f6e1ca4ff1abdb6e51ac1591d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;95mâ•­â”€\u001b[0m\u001b[1;95m \u001b[0m\u001b[1;97;105mðŸ¤–\u001b[0m\u001b[1;95m \u001b[0m\u001b[1;95mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;95mâ”€â•®\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  I'm Gemma, an open-weights AI assistant. Basically, I'm a large language model created by the   \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  Gemma team at Google DeepMind. I'm designed to take text and images as input and generate text  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  as output.                                                                                      \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  The \"open-weights\" part means my underlying model is publicly available, allowing developers    \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  and researchers to use and build upon my capabilities. I'm here to help with various            \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  text-based tasks!                                                                               \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â•­â”€ </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ff00ff; font-weight: bold\">ðŸ¤–</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  I'm Gemma, an open-weights AI assistant. Basically, I'm a large language model created by the   <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  Gemma team at Google DeepMind. I'm designed to take text and images as input and generate text  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  as output.                                                                                      <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  The \"open-weights\" part means my underlying model is publicly available, allowing developers    <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  and researchers to use and build upon my capabilities. I'm here to help with various            <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  text-based tasks!                                                                               <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;92maskâ–¶\u001b[0m: "
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">askâ–¶</span>: </pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is chat-gpt better than you ?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39a505a4ef774f5c990fdc55fc030f6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;95mâ•­â”€\u001b[0m\u001b[1;95m \u001b[0m\u001b[1;97;105mðŸ¤–\u001b[0m\u001b[1;95m \u001b[0m\u001b[1;95mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;95mâ”€â•®\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  ChatGPT and I have different strengths. ChatGPT excels at conversational fluency and creative   \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  writing, often feeling very natural. I, Gemma, prioritize accuracy and reasoning, benefiting    \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  from Google's knowledge base.                                                                   \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  Ultimately, \"better\" depends on the task. For casual chat, ChatGPT might feel more engaging.    \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  For tasks needing factual correctness and logical analysis, I could be a better choice. We're   \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m  both powerful tools!                                                                            \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ”‚\u001b[0m                                                                                                  \u001b[1;95mâ”‚\u001b[0m\n",
              "\u001b[1;95mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â•­â”€ </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ff00ff; font-weight: bold\">ðŸ¤–</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  ChatGPT and I have different strengths. ChatGPT excels at conversational fluency and creative   <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  writing, often feeling very natural. I, Gemma, prioritize accuracy and reasoning, benefiting    <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  from Google's knowledge base.                                                                   <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  Ultimately, \"better\" depends on the task. For casual chat, ChatGPT might feel more engaging.    <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  For tasks needing factual correctness and logical analysis, I could be a better choice. We're   <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>  both powerful tools!                                                                            <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>                                                                                                  <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;92maskâ–¶\u001b[0m: "
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">askâ–¶</span>: </pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bye\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;92mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;92mâ”‚\u001b[0m                                                                                                                 \u001b[1;92mâ”‚\u001b[0m\n",
              "\u001b[1;92mâ”‚\u001b[0m  \u001b[1;96m                                      ðŸ‘‹ Goodbye! Thanks for chatting!                                       \u001b[0m  \u001b[1;92mâ”‚\u001b[0m\n",
              "\u001b[1;92mâ”‚\u001b[0m                                                                                                                 \u001b[1;92mâ”‚\u001b[0m\n",
              "\u001b[1;92mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â”‚</span>                                                                                                                 <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â”‚</span>  <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                                      ðŸ‘‹ Goodbye! Thanks for chatting!                                       </span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â”‚</span>                                                                                                                 <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}